{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4147974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8), (614,), (154,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the pre-processed.txt file\n",
    "file_path = 'csie.ntu.edu.tw_~cjlin_libsvmtools_datasets_binary_diabetes_scale.txt'\n",
    "data = pd.read_csv(file_path, sep=\" \", header=None, engine='python')\n",
    "\n",
    "# Load the dataload_svmlight_file\n",
    "X, y = load_svmlight_file(file_path)\n",
    "\n",
    "# Transforming the labels from -1 and 1 to 0 and 1\n",
    "y = np.where(y == -1, 0, 1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the dimensions of the training and testing sets\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6069ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Perceptron model\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(8, 1)  # 8 input features, 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(x))  # Sigmoid activation for binary classification\n",
    "\n",
    "# Create an instance of the Perceptron model\n",
    "perceptron_model = Perceptron()\n",
    "\n",
    "# Display the model architecture\n",
    "perceptron_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0f3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader objects for training and testing data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c468387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(perceptron_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "007aa762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7015665173530579\n",
      "Epoch 2/10, Loss: 0.6120850443840027\n",
      "Epoch 3/10, Loss: 0.6276235580444336\n",
      "Epoch 4/10, Loss: 0.822481632232666\n",
      "Epoch 5/10, Loss: 0.535129189491272\n",
      "Epoch 6/10, Loss: 0.4325692653656006\n",
      "Epoch 7/10, Loss: 0.8036440014839172\n",
      "Epoch 8/10, Loss: 0.5276857018470764\n",
      "Epoch 9/10, Loss: 0.829826831817627\n",
      "Epoch 10/10, Loss: 0.4296860992908478\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "perceptron_model.train()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Lists to store loss and accuracy history\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get the data and labels\n",
    "        data, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = perceptron_model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c5628f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.53%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "perceptron_model.eval()\n",
    "\n",
    "# No gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        outputs = perceptron_model(data)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_minus = optim.SGD(perceptron_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee9ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7141383290290833\n",
      "Epoch 2/50, Loss: 0.5725544095039368\n",
      "Epoch 3/50, Loss: 0.7920497059822083\n",
      "Epoch 4/50, Loss: 0.645887553691864\n",
      "Epoch 5/50, Loss: 0.6463311314582825\n",
      "Epoch 6/50, Loss: 0.8001843094825745\n",
      "Epoch 7/50, Loss: 0.6408202052116394\n",
      "Epoch 8/50, Loss: 0.642798900604248\n",
      "Epoch 9/50, Loss: 0.5589042901992798\n",
      "Epoch 10/50, Loss: 0.8057024478912354\n",
      "Epoch 11/50, Loss: 0.646211564540863\n",
      "Epoch 12/50, Loss: 0.5716606974601746\n",
      "Epoch 13/50, Loss: 0.4868420660495758\n",
      "Epoch 14/50, Loss: 0.6435626745223999\n",
      "Epoch 15/50, Loss: 0.7167038917541504\n",
      "Epoch 16/50, Loss: 0.49121227860450745\n",
      "Epoch 17/50, Loss: 0.8009834885597229\n",
      "Epoch 18/50, Loss: 0.49125242233276367\n",
      "Epoch 19/50, Loss: 0.6413031220436096\n",
      "Epoch 20/50, Loss: 0.6379707455635071\n",
      "Epoch 21/50, Loss: 0.5642470717430115\n",
      "Epoch 22/50, Loss: 0.5651258826255798\n",
      "Epoch 23/50, Loss: 0.648897647857666\n",
      "Epoch 24/50, Loss: 0.6388258934020996\n",
      "Epoch 25/50, Loss: 0.5701165199279785\n",
      "Epoch 26/50, Loss: 0.7179558873176575\n",
      "Epoch 27/50, Loss: 0.4861123263835907\n",
      "Epoch 28/50, Loss: 0.639426052570343\n",
      "Epoch 29/50, Loss: 0.6396615505218506\n",
      "Epoch 30/50, Loss: 0.6463623642921448\n",
      "Epoch 31/50, Loss: 0.6403564810752869\n",
      "Epoch 32/50, Loss: 0.5666188597679138\n",
      "Epoch 33/50, Loss: 0.8008992075920105\n",
      "Epoch 34/50, Loss: 0.5669266581535339\n",
      "Epoch 35/50, Loss: 0.6385822892189026\n",
      "Epoch 36/50, Loss: 0.5621752142906189\n",
      "Epoch 37/50, Loss: 0.4903598129749298\n",
      "Epoch 38/50, Loss: 0.6393011212348938\n",
      "Epoch 39/50, Loss: 0.4760531187057495\n",
      "Epoch 40/50, Loss: 0.487933874130249\n",
      "Epoch 41/50, Loss: 0.5663254857063293\n",
      "Epoch 42/50, Loss: 0.6517966985702515\n",
      "Epoch 43/50, Loss: 0.5648913979530334\n",
      "Epoch 44/50, Loss: 0.48046746850013733\n",
      "Epoch 45/50, Loss: 0.487512469291687\n",
      "Epoch 46/50, Loss: 0.5742198824882507\n",
      "Epoch 47/50, Loss: 0.6481747031211853\n",
      "Epoch 48/50, Loss: 0.6474442481994629\n",
      "Epoch 49/50, Loss: 0.4774380028247833\n",
      "Epoch 50/50, Loss: 0.8793072700500488\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "perceptron_model.train()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_minus.zero_grad()\n",
    "\n",
    "        # Get the data and labels\n",
    "        data, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = perceptron_model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer_minus.step()\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc80340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.26%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "perceptron_model.eval()\n",
    "\n",
    "# No gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        outputs = perceptron_model(data)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21553ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "perceptron_multi_model = MLP()\n",
    "\n",
    "# Display the model architecture\n",
    "perceptron_multi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d062d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7164037823677063\n",
      "Epoch 2/50, Loss: 0.5732870697975159\n",
      "Epoch 3/50, Loss: 0.6438849568367004\n",
      "Epoch 4/50, Loss: 0.5631062388420105\n",
      "Epoch 5/50, Loss: 0.715388834476471\n",
      "Epoch 6/50, Loss: 0.6457738876342773\n",
      "Epoch 7/50, Loss: 0.5664060711860657\n",
      "Epoch 8/50, Loss: 0.5675079822540283\n",
      "Epoch 9/50, Loss: 0.5703784823417664\n",
      "Epoch 10/50, Loss: 0.5746790766716003\n",
      "Epoch 11/50, Loss: 0.7225861549377441\n",
      "Epoch 12/50, Loss: 0.7191927433013916\n",
      "Epoch 13/50, Loss: 0.575002908706665\n",
      "Epoch 14/50, Loss: 0.49579715728759766\n",
      "Epoch 15/50, Loss: 0.6488012671470642\n",
      "Epoch 16/50, Loss: 0.4916648864746094\n",
      "Epoch 17/50, Loss: 0.6391814351081848\n",
      "Epoch 18/50, Loss: 0.5715391635894775\n",
      "Epoch 19/50, Loss: 0.6448408961296082\n",
      "Epoch 20/50, Loss: 0.6394392848014832\n",
      "Epoch 21/50, Loss: 0.7171538472175598\n",
      "Epoch 22/50, Loss: 0.7213723063468933\n",
      "Epoch 23/50, Loss: 0.7161199450492859\n",
      "Epoch 24/50, Loss: 0.5648983716964722\n",
      "Epoch 25/50, Loss: 0.645399808883667\n",
      "Epoch 26/50, Loss: 0.7176792621612549\n",
      "Epoch 27/50, Loss: 0.7188289761543274\n",
      "Epoch 28/50, Loss: 0.5660170912742615\n",
      "Epoch 29/50, Loss: 0.7234604954719543\n",
      "Epoch 30/50, Loss: 0.7199566960334778\n",
      "Epoch 31/50, Loss: 0.49425771832466125\n",
      "Epoch 32/50, Loss: 0.5695785284042358\n",
      "Epoch 33/50, Loss: 0.569128692150116\n",
      "Epoch 34/50, Loss: 0.7218592166900635\n",
      "Epoch 35/50, Loss: 0.5662422776222229\n",
      "Epoch 36/50, Loss: 0.6457914710044861\n",
      "Epoch 37/50, Loss: 0.49599984288215637\n",
      "Epoch 38/50, Loss: 0.7135181427001953\n",
      "Epoch 39/50, Loss: 0.5023988485336304\n",
      "Epoch 40/50, Loss: 0.6450267434120178\n",
      "Epoch 41/50, Loss: 0.572454571723938\n",
      "Epoch 42/50, Loss: 0.4940181076526642\n",
      "Epoch 43/50, Loss: 0.6438984274864197\n",
      "Epoch 44/50, Loss: 0.7222385406494141\n",
      "Epoch 45/50, Loss: 0.7158017158508301\n",
      "Epoch 46/50, Loss: 0.500283420085907\n",
      "Epoch 47/50, Loss: 0.8001640439033508\n",
      "Epoch 48/50, Loss: 0.7945621609687805\n",
      "Epoch 49/50, Loss: 0.7217531204223633\n",
      "Epoch 50/50, Loss: 0.5713515281677246\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "perceptron_multi_model.train()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_minus.zero_grad()\n",
    "\n",
    "        # Get the data and labels\n",
    "        data, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = perceptron_multi_model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer_minus.step()\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33317440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35.71%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "perceptron_multi_model.eval()\n",
    "\n",
    "# No gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        outputs = perceptron_multi_model(data)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0c4096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPWithDropout(\n",
       "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLPWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 16)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "perceptron_multi_model_withdropout = MLPWithDropout()\n",
    "\n",
    "# Display the model architecture\n",
    "perceptron_multi_model_withdropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aedd731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5412494540214539\n",
      "Epoch 2/50, Loss: 0.8283233642578125\n",
      "Epoch 3/50, Loss: 0.6427968144416809\n",
      "Epoch 4/50, Loss: 0.6482671499252319\n",
      "Epoch 5/50, Loss: 0.44069501757621765\n",
      "Epoch 6/50, Loss: 0.5423381924629211\n",
      "Epoch 7/50, Loss: 0.7312679290771484\n",
      "Epoch 8/50, Loss: 0.7296120524406433\n",
      "Epoch 9/50, Loss: 0.631685197353363\n",
      "Epoch 10/50, Loss: 0.7379059791564941\n",
      "Epoch 11/50, Loss: 0.551443338394165\n",
      "Epoch 12/50, Loss: 0.6309296488761902\n",
      "Epoch 13/50, Loss: 0.543404757976532\n",
      "Epoch 14/50, Loss: 0.6357700824737549\n",
      "Epoch 15/50, Loss: 0.5420815348625183\n",
      "Epoch 16/50, Loss: 0.43958377838134766\n",
      "Epoch 17/50, Loss: 0.5459477305412292\n",
      "Epoch 18/50, Loss: 0.5440415143966675\n",
      "Epoch 19/50, Loss: 0.5393155813217163\n",
      "Epoch 20/50, Loss: 0.5409367680549622\n",
      "Epoch 21/50, Loss: 0.9176733493804932\n",
      "Epoch 22/50, Loss: 0.5479876399040222\n",
      "Epoch 23/50, Loss: 0.6328743100166321\n",
      "Epoch 24/50, Loss: 0.5474632382392883\n",
      "Epoch 25/50, Loss: 0.5443152785301208\n",
      "Epoch 26/50, Loss: 0.46016108989715576\n",
      "Epoch 27/50, Loss: 0.733694851398468\n",
      "Epoch 28/50, Loss: 0.6450150012969971\n",
      "Epoch 29/50, Loss: 0.5440030097961426\n",
      "Epoch 30/50, Loss: 0.7349069714546204\n",
      "Epoch 31/50, Loss: 0.6468057036399841\n",
      "Epoch 32/50, Loss: 0.633320152759552\n",
      "Epoch 33/50, Loss: 0.8180524706840515\n",
      "Epoch 34/50, Loss: 0.8326776027679443\n",
      "Epoch 35/50, Loss: 0.6362822651863098\n",
      "Epoch 36/50, Loss: 0.5435704588890076\n",
      "Epoch 37/50, Loss: 0.5432831645011902\n",
      "Epoch 38/50, Loss: 0.6485365033149719\n",
      "Epoch 39/50, Loss: 0.639234721660614\n",
      "Epoch 40/50, Loss: 0.5472001433372498\n",
      "Epoch 41/50, Loss: 0.7471437454223633\n",
      "Epoch 42/50, Loss: 0.6557217240333557\n",
      "Epoch 43/50, Loss: 0.6431149244308472\n",
      "Epoch 44/50, Loss: 0.4506666958332062\n",
      "Epoch 45/50, Loss: 0.7224916815757751\n",
      "Epoch 46/50, Loss: 0.7359923720359802\n",
      "Epoch 47/50, Loss: 0.7325271964073181\n",
      "Epoch 48/50, Loss: 0.5400092005729675\n",
      "Epoch 49/50, Loss: 0.8208887577056885\n",
      "Epoch 50/50, Loss: 0.6402550339698792\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "perceptron_multi_model_withdropout.train()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_minus.zero_grad()\n",
    "\n",
    "        # Get the data and labels\n",
    "        data, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = perceptron_multi_model_withdropout(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer_minus.step()\n",
    "\n",
    "    # Print loss for every epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af701061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.29%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "perceptron_multi_model_withdropout.eval()\n",
    "\n",
    "# No gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        outputs = perceptron_multi_model_withdropout(data)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
